countries <- read.csv(file = 'DATA301_A5_datasets/ghcnd-countries.csv')
head(countries)
countries <- read.csv(file = 'DATA301_A5_datasets/ghcnd-countries.csv', header = FALSE)
head(countries)
stations <- read.csv(file = 'DATA301_A5_datasets/ghcnd-stations.csv')
head(stations)
stations <- read.csv(file = 'DATA301_A5_datasets/ghcnd-stations.csv', header = FALSE)
head(stations)
countries <- read.csv(file = 'DATA301_A5_datasets/ghcnd-countries.csv', header = FALSE)
names(countries) <- c("country_code", "country_name")
head(countries)
stations <- read.csv(file = 'DATA301_A5_datasets/ghcnd-stations.csv', header = FALSE)
names(stations) <- c("station_id", "latitude", "longitude", "elevation_m",
"station_name", "local_id")
head(stations)
stations[,"station_id"]
substr(stations[,"station_id"], 1, 2)
stations["country_code"] <- substr(stations[,"station_id"], 1, 2)
head(stations)
# how many unique country codes are missing from the countries dataset but are present in the stations dataset,
setdiff(stations$country_code, countries$country_code)
library(dplyr)
stations %>% filter(!country_code %in% countries$country_code)
# how many unique country codes are missing from the countries dataset but are present in the stations dataset,
setdiff(stations$country_code, countries$country_code)
# how many unique country codes are missing from the countries dataset but are present in the stations dataset,
len(setdiff(stations$country_code, countries$country_code))
# how many unique country codes are missing from the countries dataset but are present in the stations dataset,
length(setdiff(stations$country_code, countries$country_code))
sum(is.na(stations$station_id))
is.na(stations$station_id)
df = merge(x=stations, y=countries, by="country_code")
df
length(setdiff(countries$country_code, stations$country_code))
# Chunk 1
folder_path <- "DATA301_A5_datasets/"
library(tidyr)
# Chunk 2
df_list <- lapply(stations$station_id, function(id) {
# Chunk 3
file_path <- paste0(folder_path, id, ".dly")
# Chunk 4
if (!file.exists(file_path)) return(NULL)
else {
# Chunk 5
df <- read.fwf(file_path, header=FALSE,
widths=c(11,4,2,4,rep(c(5,1,1,1),times=31)))
# Chunk 6
names(df) <- c("station_id","year","month","element",
paste0(rep(c("value","mflag","qflag","sflag"),times=31),rep(1:31,each=4)))
# Chunk 7
df_long <-  pivot_longer(df, 5:128,
names_to = c(".value", "day"),
names_pattern = "([a-z][a-z][a-z][a-z][a-z])(.+)")
# Chunk 8
df_reduced <- filter(df_long, element %in% c("PRCP","TMAX","TMIN"))
}
return(df_reduced)
})
# Chunk 9
df_list <- df_list[!sapply(df_list,is.null)]
countries <- read.csv(file = 'DATA301_A5_datasets/ghcnd-countries.csv', header = FALSE)
names(countries) <- c("country_code", "country_name")
head(countries)
stations <- read.csv(file = 'DATA301_A5_datasets/ghcnd-stations.csv', header = FALSE)
names(stations) <- c("station_id", "latitude", "longitude", "elevation_m",
"station_name", "local_id")
head(stations)
stations["country_code"] <- substr(stations[,"station_id"], 1, 2)
head(stations)
length(setdiff(stations$country_code, countries$country_code))
sum(is.na(stations$station_id))
stations_countries = merge(x=stations, y=countries, by="country_code")
head(stations_countries)
library(dplyr)
# Chunk 1
folder_path <- "DATA301_A5_datasets/"
library(tidyr)
# Chunk 2
df_list <- lapply(stations$station_id, function(id) {
# Chunk 3
file_path <- paste0(folder_path, id, ".dly")
# Chunk 4
if (!file.exists(file_path)) return(NULL)
else {
# Chunk 5
df <- read.fwf(file_path, header=FALSE,
widths=c(11,4,2,4,rep(c(5,1,1,1),times=31)))
# Chunk 6
names(df) <- c("station_id","year","month","element",
paste0(rep(c("value","mflag","qflag","sflag"),times=31),rep(1:31,each=4)))
# Chunk 7
df_long <-  pivot_longer(df, 5:128,
names_to = c(".value", "day"),
names_pattern = "([a-z][a-z][a-z][a-z][a-z])(.+)")
# Chunk 8
df_reduced <- filter(df_long, element %in% c("PRCP","TMAX","TMIN"))
}
return(df_reduced)
})
# Chunk 9
df_list <- df_list[!sapply(df_list,is.null)]
df_combined <- bind_rows(df_list)
library(tidyverse)
library(lubridate)
df_combined <- df_combined %>%
mutate(date = make_date(year, month, day))
df_combined$value[df_combined$value == -9999] <- NA
df_combined$mflag[df_combined$mflag == " "] <- NA
df_combined$qflag[df_combined$qflag == " "] <- NA
df_combined$sflag[df_combined$sflag == " "] <- NA
stations_countries_weather <- merge(x=stations_countries, y=df_combined, by="station_id", all.x=TRUE)
max_min_date <- stations_countries_weather %>%
group_by(station_id) %>%
summarise(
earliestDate = min(date, na.rm = TRUE),
latestDate = max(date, na.rm = TRUE))
max_min_date[sapply(max_min_date, is.infinite)] <- NA
max(max_min_date$earliestDate, na.rm = TRUE)
min(max_min_date$latestDate, na.rm = TRUE)
library(timetk)
stations_countries_weather_1994_2008 <- filter_by_time(stations_countries_weather,
.date_var = date, .start_date = "1994-01-01",
.end_date = "2008-01-01")
stations_countries_weather_1994_2008
stations_countries_weather_1994_2008 %>%
filter(elevation_m >= 10)
countries<- c("New Caledonia", "Fiji", "Vanuatu", "New Zealand")
stations_countries_weather_1994_2008 %>%
filter(elevation_m >= 10 & country_name %in% countries)
stations_countries_weather_1994_2008
unique(stations_countries_weather_1994_2008$country_name)
countries<- c("New Caledonia", "Fiji", "Vanuatu", "New Zealand")
abc <- stations_countries_weather_1994_2008 %>%
filter(elevation_m >= 10 & country_name %in% countries)
unique(abc$country_name)
countries<- c("New Caledonia [France]", "Fiji", "Vanuatu", "New Zealand")
abc <- stations_countries_weather_1994_2008 %>%
filter(elevation_m >= 10 & country_name %in% countries)
unique(abc$country_name)
countries<- c("New Caledonia [France]", "Fiji", "Vanuatu", "New Zealand")
stations_countries_weather_1994_2008 %>%
filter(elevation_m >= 10 & country_name %in% countries)
countries<- c("New Caledonia [France]", "Fiji", "Vanuatu", "New Zealand")
stations_countries_weather_1994_2008 %>%
filter(elevation_m >= 10 & country_name %in% countries)
countries<- c("New Caledonia [France]", "Fiji", "Vanuatu", "New Zealand")
stations_countries_weather_1994_2008_con <- stations_countries_weather_1994_2008 %>%
filter(elevation_m >= 10 & country_name %in% countries)
stations_countries_weather_1994_2008_con
q1o <- read.csv(file = 'DATA301_A5_datasets/Q1o_onwards.csv')
q1o
sum(is.na(q1o$PRCP))
sum(is.na(q1o$TMAX))
sum(is.na(q1o$TMIN))
sum(is.na(q1o$TMIN))
unique(q1o[,c(TMAX, TMIN, PCRP)])
sum(is.na(q1o$TMIN))
unique(q1o[,c("TMAX", "TMIN", "PCRP")])
sum(is.na(q1o$TMIN))
unique(q1o$TMIN)
q1o$PRCP <- q1o$PRCP / 10
#as.numeric(as.character(test$locations)) / 10
q1o$PRCP <- q1o$PRCP / 10
q1o$PRCP <- q1o$PRCP / 10
q1o$month <- q1o$month / 10
q1o
#as.numeric(as.character(test$locations)) / 10
q1o$PRCP <- q1o$PRCP / 10
q1o$PRCP <- q1o$PRCP / 10
q1o$month <- q1o$month * 10
q1o
#as.numeric(as.character(test$locations)) / 10
q1o <- read.csv(file = 'DATA301_A5_datasets/Q1o_onwards.csv')
q1o$PRCP <- q1o$PRCP / 10
q1o$TMAX <- q1o$TMAX / 10
q1o$TMIN <- q1o$TMIN / 10
unique(q1o$TMIN )
unique(q1o$TMAX )
unique(q1o$PRCP )
q1o
q1o %>%
group_by(year, country_name)
q1o %>%
group_by(year, country_name) %>%
summarise(highest_rainfall = max(PRCP),
highest_temperature = max(TMAX),
lowest_temperature = min(TMIN))
q1o %>%
group_by(year, country_name) %>%
summarise(highest_rainfall = max(PRCP),
highest_temperature = max(TMAX),
lowest_temperature = min(TMIN),
na.rm = TRUE)
q1o %>%
group_by(year, country_name) %>%
summarise(highest_rainfall = max(PRCP, na.rm = TRUE),
highest_temperature = max(TMAX),
lowest_temperature = min(TMIN))
q1o %>%
group_by(year, country_name) %>%
summarise(highest_rainfall = max(PRCP, na.rm = TRUE),
highest_temperature = max(TMAX, na.rm = TRUE),
lowest_temperature = min(TMIN, na.rm = TRUE))
na.omit(q1o) %>%
group_by(year, country_name) %>%
summarise(highest_rainfall = max(PRCP, na.rm = TRUE),
highest_temperature = max(TMAX, na.rm = TRUE),
lowest_temperature = min(TMIN, na.rm = TRUE))
na.omit(q1o) %>%
group_by(year, country_name) %>%
summarise(highest_rainfall = max(PRCP, na.rm = TRUE),
highest_temperature = max(TMAX, na.rm = TRUE),
lowest_temperature = min(TMIN, na.rm = TRUE))
knitr::opts_chunk$set(echo = FALSE)
require(ggplot2)
require(ggthemes)
require(gridExtra)
require(pander)
require(xtable)
require(bookdown)
require(psych)
require(MASS)
require(ggord)
require(klaR)
student
student=read.table("../../Data/CSV/student-mat.csv",sep=";",header=TRUE)
df_num = data.frame(student$age, student$absences,
student$G1, student$G2, student$G3)
student$school <- as.factor(student$school)
student$sex <- as.factor(student$sex)
student$failures <- as.factor(student$failures)
df = data.frame(student$school,student$sex,student$failures)
names(df) = c("School", "Sex", "Failures")
names(df_num) <- c("age", "absences", "G1","G2","G3")
student
df
df_num
df_num[, -5]
df_num
ggcorrplot(cor(df_num),
method = "circle",
hc.order = TRUE,
type = "lower")
knitr::opts_chunk$set(echo = FALSE)
require(ggplot2)
require(ggcorrplot)
require(ggthemes)
require(gridExtra)
require(pander)
require(xtable)
require(bookdown)
require(psych)
require(MASS)
require(ggord)
require(klaR)
ggcorrplot(cor(df_num),
method = "circle",
hc.order = TRUE,
type = "lower")
lp <- list()
df_all <- cbind(df, df_num)
for (i in 1:length(names(df))){
lp[[i]] <- ggplot(df_all, aes_string(x=names(df)[i], y="G3", col = names(df)[[i]])) +
geom_boxplot(notch=TRUE) +
labs(y="Final Grade")
}
lp2 <- list()
for (i in 1:length(names(df))){
lp2[[i]] <- ggplot(df_all, aes_string(x=names(df)[i], y="absences", col = names(df)[[i]])) +
geom_boxplot(notch=TRUE) +
labs(y="Number of Absences")
}
lp3 <- list()
for (i in 1:length(names(df))){
lp3[[i]] <- ggplot(df_all, aes_string(x=names(df)[i], y="age", col = names(df)[[i]])) +
geom_boxplot(notch=TRUE) +
labs(y="Age")
}
grid.arrange(lp[[1]], lp[[2]], lp[[3]],
lp2[[1]], lp2[[2]], lp2[[3]],
lp3[[1]], lp3[[2]], lp3[[3]],ncol = 3)
