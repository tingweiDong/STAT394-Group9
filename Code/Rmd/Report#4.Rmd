---
title: 'Report #4'
author: "GROUP 9"
classoption: 12pt
output: bookdown::pdf_document2
bibliography: ../../Reference/bib/References.bib
link-citations: true
biblio_style: "apalike"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(ggplot2)
require(ggcorrplot)
require(ggthemes)
require(matlib)
require(bookdown)
require(xtable)
require(moments)
require(gridExtra)
require(GGally)
require(dplyr)
require(stats)
require(HDtest)
require(pander)
```

```{r, echo=FALSE}
#df only contains categorical column
student=read.table("../../Data/CSV/student-mat.csv",sep=";",header=TRUE)
student$school <- as.factor(student$school)
student$sex <- as.factor(student$sex)
student$failures <- as.factor(student$failures)
df = data.frame(student$school,student$sex,student$failures)
names(df) = c("School", "Sex", "Failures")

# df_num only contains numeric column
df_num = data.frame(student$age, student$absences, student$G1, student$G2, student$G3)
names(df_num) <- c("age", "absences", "G1","G2","G3")
```

# Normality Check on Numerical Variables

From previous EDA, we have found that some of the numerical variables might be normally distributed. We will closely look at the normality. Figure&nbsp;\@ref(fig:qq) shows Quantile-Quantile plot of each numerical variables. For all of the plots, the points are off from the diagonal line, indicating non-normality. 

The table \@ref(tab:test) shows the results of Shapiro Wilk test [@shapiro] for normality where they tested: $$H_0: X_i\ follows\ Normal\ distribution$$ $$H_0: X_i\ does\ not\ follow\ Normal\ distribution$$ $$where, \ i =\{Age, Absences, G1, G2, G3\}$$

All of p-values are very small (when rounded at the 3 decimal points they are zeros) so, we have strong evidence against the null hypotheses that the variables are normally distributed.

We can not apply log transformation to the variables since the variables contain zero value (e.g., some student scored zero at the test). Since the variables are not normally distributed and we can not apply log transformation, we need to find some analysis method that is robust to non-normality. 

```{r qq, fig.cap="Quantile-Quantile Normality Plot", echo=FALSE, warning=FALSE, fig.height=8}
p1 <- ggplot(df_num, aes(sample=age)) +
  stat_qq() + stat_qq_line() +
  labs(x="Theoritical Quantiles", y="Sample Quantile", title="Age")
p2 <- ggplot(df_num, aes(sample=absences)) +
  stat_qq() + stat_qq_line() +
  labs(x="Theoritical Quantiles", y="Sample Quantile", title="Absence")
p3 <- ggplot(df_num, aes(sample=G1)) +
  stat_qq() + stat_qq_line() +
  labs(x="Theoritical Quantiles", y="Sample Quantile", title="G1")
p4 <- ggplot(df_num, aes(sample=G2)) +
  stat_qq() + stat_qq_line() +
  labs(x="Theoritical Quantiles", y="Sample Quantile", title="G2")
p5 <- ggplot(df_num, aes(sample=G3)) +
  stat_qq() + stat_qq_line() +
  labs(x="Theoritical Quantiles", y="Sample Quantile", title="G3")

grid.arrange(p1, p2, p3, p4, p5, nrow = 3,ncol = 2)
```



```{r, echo=FALSE}
res <- apply(df_num, shapiro.test, MARGIN=2)
result <- data.frame(c("age", "absences", "G1", "G2", "G3"), rbind(c(res$age$statistic, res$age$p.value),
c(res$absences$statistic, res$absences$p.value),
c(res$G1$statistic, res$G1$p.value),
c(res$G2$statistic, res$G2$p.value),
c(res$G3$statistic, res$G3$p.value)))

names(result) <-  c("", "W test statistics", "P.value")
#xtable(result)
```

\begin{table}[ht]
\caption {Shapiro Wilk Test Result}
\centering
\begin{tabular}{rlrr}
  \hline
 &  & W test statistics & P.value \\ 
  \hline
1 & age & 0.91 & 0.000 \\ 
  2 & absences & 0.67 & 0.000 \\ 
  3 & G1 & 0.97 & 0.000 \\ 
  4 & G2 & 0.97 & 0.000 \\ 
  5 & G3 & 0.93 & 0.000 \\ 
   \hline
\end{tabular} (\#tab:test)
\end{table}


# Assumption checks to compare three test scores (G1, G2, and G3) by sex

Figure&nbsp;\@ref(fig:box) shows the box plot of G1, G2 and G3 by sex. It seems that male student tend to score higher than female student. We want to find whether the score differ by sex. Figure&nbsp;\@ref(fig:den) shows the density plot of tests by sex. It seems variances do not differ much by sex but they might not have normal distribution. To conduct the multivariate analysis on means of vectors of students' test score(Hotelling's $T^2$ test), we will check equal variance and normality assumptions.  

```{r box, fig.height=3, fig.cap="Boxplot", echo=FALSE, warning=FALSE, message=FALSE}
df_all <- cbind(df, df_num) 

b1 <- df_all %>%
  ggplot() +
  geom_boxplot(aes(x=Sex, y=G1, col = Sex), notch = TRUE)
b2 <- df_all %>%
  ggplot() +
  geom_boxplot(aes(x=Sex, y=G2, col = Sex), notch = TRUE)
b3 <- df_all %>%
  ggplot() +
  geom_boxplot(aes(x=Sex, y=G3, col = Sex), notch = TRUE)
grid.arrange(b1, b2, b3,ncol=3)
```

```{r den, fig.height=8, fig.cap="Density plot", echo=FALSE, warning=FALSE, message=FALSE}
g1 <- ggplot(df_all, aes(x=G1, col=Sex,
group=Sex, fill=Sex)) +
geom_density(aes(y=..density..), alpha=.7)

g2 <- ggplot(df_all, aes(x=G2, col=Sex,
group=Sex, fill=Sex)) +
geom_density(aes(y=..density..), alpha=.7)

g3 <- ggplot(df_all, aes(x=G3, col=Sex,
group=Sex, fill=Sex)) +
geom_density(aes(y=..density..), alpha=.7)

grid.arrange(g1, g2, g3,ncol=1)
```

\newpage

## Test of equality of covariance matrices

We will test equality of covariance matrices using the test discussed by [@covtest]. The hypotheses are:

$$H_0: \Sigma_{Female} = \Sigma_{Male}$$
$$H_0: \Sigma_{Female} \neq \Sigma_{Male}$$
The table \@ref(tab:covtest) shows the results from 4 tests about covariance matrix. They all returned high p-values indicating that we have very small evidence against the null hypothesis that the covariance matrices are equal. Therefore, we can assume equal covariance matrix.  

```{r, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE} 
cov_res <- testCov(subset(df_all, Sex=="F")[,-c(1:5)], subset(df_all, Sex=="M")[,-c(1:5)])
df_cov <- data.frame(c("HD", "CLX", "Scott", "LC"),
rbind(c(cov_res$HD$statistics, cov_res$HD$p.value),
c(cov_res$CLX$statistics, cov_res$CLX$p.value),
c(cov_res$Scott$statistics, cov_res$Scott$p.value),
c(cov_res[[4]]$statistics, cov_res[[4]]$p.value)))
names(df_cov) <- c("Tests", "Test Statistics", "P.values")

#xtable(df_cov)
```


\begin{table}[ht]
\caption {Multivariate covariance matrix test}
\centering
\begin{tabular}{rlrr}
  \hline
 & Tests & Test Statistics & P.values \\ 
  \hline
1 & HD & 1.01 & 0.63 \\ 
  2 & CLX & 1.01 & 0.64 \\ 
  3 & Scott & 0.66 & 0.51 \\ 
  4 & LC & -0.66 & 0.75 \\ 
   \hline
\end{tabular} (\#tab:covtest)
\end{table}

## Test for normality of each distribution

We will conduct the hypotheses test to check normality of each distributions by using Shapiro Wilk Test [@shapiro]. The hypotheses are:

$$H_0: X_{i,j}\ follows\ Normal\ distribution$$ $$H_0: X_{i,j}\ does\ not\ follow\ Normal\ distribution$$ $$where, \ i =\{Female, Male\}\ and\ j = \{G1, G2, G3\}$$

So, in total, we have conducted six hypothesis tests.

The table \@ref(tab:normf) and the table \@ref(tab:normm) show the results of Shapiro Wilk test on each tests score(G1, G2, and G3) by sex respectively. Since all p-values are very small we have very strong evidence against that the variables have normal distribution, indicating the violation of normality assumptions. Since the normality assumptions are violated we should not conduct Hotelling's $T^2$ test. We need to find some alternative methods to find whether the tests score differ among sex.

```{r, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
res <- apply(df_num[df_all$Sex == "F", ], shapiro.test, MARGIN=2)
result.F <- data.frame(c("G1", "G2", "G3"),
rbind(c(res$G1$statistic, res$G1$p.value),
c(res$G2$statistic, res$G2$p.value),
c(res$G3$statistic, res$G3$p.value)))

names(result.F) <-  c("Female", "W test statistics", "P.value")
#xtable(result.F)
```

\begin{table}[ht]
\caption {Normality test on Female tests score}
\centering
\begin{tabular}{rlrr}
  \hline
 & Female & W test statistics & P.value \\ 
  \hline
1 & G1 & 0.97 & 0.00 \\ 
  2 & G2 & 0.97 & 0.00 \\ 
  3 & G3 & 0.92 & 0.00 \\ 
   \hline
\end{tabular} (\#tab:normf)
\end{table}

```{r, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
res <- apply(df_num[df_all$Sex == "M", ], shapiro.test, MARGIN=2)
result.M <- data.frame(c("G1", "G2", "G3"),
rbind(c(res$G1$statistic, res$G1$p.value),
c(res$G2$statistic, res$G2$p.value),
c(res$G3$statistic, res$G3$p.value)))

names(result.M) <-  c("Male", "W test statistics", "P.value")
#xtable(result.M)
```

\begin{table}[ht]
\caption {Normality test on Male tests score}
\centering
\begin{tabular}{rlrr}
  \hline
 & Male & W test statistics & P.value \\ 
  \hline
1 & G1 & 0.98 & 0.01 \\ 
  2 & G2 & 0.97 & 0.00 \\ 
  3 & G3 & 0.93 & 0.00 \\ 
   \hline
\end{tabular} (\#tab:normm)
\end{table}

\newpage

## Kruskal-Wallis test

Since we can not conduct Hotelling's $T^2$ test we will just test the significant difference in G3 scores by sex (we won't do the test for G1 and G2 because we want to control for family wise error). We used Kruskal Wallis test [@kruskal]:

$$H_0: Medians\ of\ G3\ test\ scores\ do\ not\ differ\ among\ sex$$
$$H_1: Medians\ of\ G3\ test\ scores\ differ\ among\ sex$$
Kruskal-Wallis test is nonparametric test so, it is robust to non-normality. The table 5 shows the result of Kruskal-Wallis test. Since p-value is around 0.05, we conclude that we have some evidence against the null hypothesis that the medians of G3 scores are same among sex. 

```{r kruskal, echo = FALSE}
pander(kruskal.test(G1 ~ Sex, data = df_all))
```


\newpage

# The Mahalanobis distance

```{r distance, fig.cap="Mahalanobis distances Plot", echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
mu.hat <- colMeans(df_num)
Sigma.hat <- cov(df_num)

dM <- mahalanobis(df_num, center=mu.hat, cov=Sigma.hat)
upper.quantiles <- qchisq(c(.9, .95, .99), df=9)
density.at.quantiles <- dchisq(x=upper.quantiles, df=9)
cut.points <- data.frame(upper.quantiles, density.at.quantiles)
ggplot(data.frame(dM), aes(x=dM)) +
  geom_histogram(aes(y=..density..), bins=nclass.FD(dM),
                 fill="white", col="black") +
  geom_rug() +
  stat_function(fun="dchisq", args = list(df=9),
                col="red", size=2, alpha=.7, xlim=c(0,25)) +
  geom_segment(data=cut.points,
               aes(x=upper.quantiles, xend=upper.quantiles,
                 y=rep(0,3), yend=density.at.quantiles),
             col="blue", size=2) +
xlab("Mahalanobis distances and cut points") +
ylab("Histogram and density")
```

```{r dM, echo = FALSE}
df_num$dM <- dM
df_num$surprise <- cut(df_num$dM,
                 breaks= c(0, upper.quantiles, Inf),
                 labels=c("Typical", "Somewhat", "Surprising", "Very"))
pander(table(df_num$surprise))
```


\newpage

# References 